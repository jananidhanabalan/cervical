{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d4225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5d0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Clean Data_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80c476af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f4230a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of sexual partners</th>\n",
       "      <th>First sexual intercourse</th>\n",
       "      <th>Num of pregnancies</th>\n",
       "      <th>Smokes</th>\n",
       "      <th>Smokes (years)</th>\n",
       "      <th>Smokes (packs/year)</th>\n",
       "      <th>Hormonal Contraceptives</th>\n",
       "      <th>Hormonal Contraceptives (years)</th>\n",
       "      <th>IUD</th>\n",
       "      <th>...</th>\n",
       "      <th>STDs:HIV</th>\n",
       "      <th>STDs: Number of diagnosis</th>\n",
       "      <th>Dx:Cancer</th>\n",
       "      <th>Dx:CIN</th>\n",
       "      <th>Dx:HPV</th>\n",
       "      <th>Dx</th>\n",
       "      <th>Hinselmann</th>\n",
       "      <th>Schiller</th>\n",
       "      <th>Citology</th>\n",
       "      <th>Biopsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Number of sexual partners  First sexual intercourse  \\\n",
       "0   18                        4.0                      15.0   \n",
       "1   15                        1.0                      14.0   \n",
       "2   34                        1.0                      16.0   \n",
       "3   52                        5.0                      16.0   \n",
       "4   46                        3.0                      21.0   \n",
       "\n",
       "   Num of pregnancies  Smokes  Smokes (years)  Smokes (packs/year)  \\\n",
       "0                 1.0     0.0             0.0                  0.0   \n",
       "1                 1.0     0.0             0.0                  0.0   \n",
       "2                 1.0     0.0             0.0                  0.0   \n",
       "3                 4.0     1.0            37.0                 37.0   \n",
       "4                 4.0     0.0             0.0                  0.0   \n",
       "\n",
       "   Hormonal Contraceptives  Hormonal Contraceptives (years)  IUD  ...  \\\n",
       "0                      0.0                              0.0  0.0  ...   \n",
       "1                      0.0                              0.0  0.0  ...   \n",
       "2                      0.0                              0.0  0.0  ...   \n",
       "3                      1.0                              3.0  0.0  ...   \n",
       "4                      1.0                             15.0  0.0  ...   \n",
       "\n",
       "   STDs:HIV  STDs: Number of diagnosis  Dx:Cancer  Dx:CIN  Dx:HPV  Dx  \\\n",
       "0       0.0                          0          0       0       0   0   \n",
       "1       0.0                          0          0       0       0   0   \n",
       "2       0.0                          0          0       0       0   0   \n",
       "3       0.0                          0          1       0       1   0   \n",
       "4       0.0                          0          0       0       0   0   \n",
       "\n",
       "   Hinselmann  Schiller  Citology  Biopsy  \n",
       "0           0         0         0       0  \n",
       "1           0         0         0       0  \n",
       "2           0         0         0       0  \n",
       "3           0         0         0       0  \n",
       "4           0         0         0       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "936fbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6557c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "40e93add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 24)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "78ff6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e42165ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "707983b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05108938, 0.05733258, 0.05237305, 0.06887332, 0.04411919,\n",
       "       0.00657872, 0.01311584, 0.01205263, 0.01586604, 0.05158761,\n",
       "       0.01239303, 0.01548671, 0.00793369, 0.00914611, 0.00709803,\n",
       "       0.0068774 , 0.01113966, 0.01000451, 0.00862285, 0.00663446,\n",
       "       0.0098412 , 0.14420455, 0.32515541, 0.05247403])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "58bf5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(clf, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e5398468",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9dbb68c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 9)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b0ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18866b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Biopsy',axis=1)\n",
    "y = df['Biopsy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "137eb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151ade9",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dfd136bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f4453ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d785bc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9ed0ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e5df9940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9575971731448764\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       263\n",
      "           1       0.68      0.75      0.71        20\n",
      "\n",
      "    accuracy                           0.96       283\n",
      "   macro avg       0.83      0.86      0.85       283\n",
      "weighted avg       0.96      0.96      0.96       283\n",
      "\n",
      "\n",
      "\n",
      "[[256   7]\n",
      " [  5  15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print('Accuracy Score:',accuracy_score(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146e1a1",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54dc222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c5110b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d671875",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ce9ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6eb7c321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9575971731448764\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       263\n",
      "           1       0.72      0.65      0.68        20\n",
      "\n",
      "    accuracy                           0.96       283\n",
      "   macro avg       0.85      0.82      0.83       283\n",
      "weighted avg       0.96      0.96      0.96       283\n",
      "\n",
      "\n",
      "\n",
      "[[258   5]\n",
      " [  7  13]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:',accuracy_score(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31b4d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c68bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(units=24,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(units=12,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "# compiler\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "677da903",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4dfaffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "18/18 [==============================] - 1s 10ms/step - loss: 57.0194 - val_loss: 3.7667\n",
      "Epoch 2/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 37.0937 - val_loss: 2.7356\n",
      "Epoch 3/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 32.2292 - val_loss: 4.6403\n",
      "Epoch 4/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 25.1789 - val_loss: 5.8493\n",
      "Epoch 5/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 20.0295 - val_loss: 6.5206\n",
      "Epoch 6/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 17.3469 - val_loss: 6.9708\n",
      "Epoch 7/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 14.0077 - val_loss: 6.9326\n",
      "Epoch 8/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 11.6256 - val_loss: 7.3331\n",
      "Epoch 9/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.1645 - val_loss: 7.2841\n",
      "Epoch 10/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.4391 - val_loss: 7.0997\n",
      "Epoch 11/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.8011 - val_loss: 6.9316\n",
      "Epoch 12/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7199 - val_loss: 6.4799\n",
      "Epoch 13/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 11.0407 - val_loss: 5.8303\n",
      "Epoch 14/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.6401 - val_loss: 5.2582\n",
      "Epoch 15/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.7939 - val_loss: 4.8080\n",
      "Epoch 16/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9119 - val_loss: 4.4473\n",
      "Epoch 17/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9388 - val_loss: 4.1378\n",
      "Epoch 18/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.1776 - val_loss: 3.8413\n",
      "Epoch 19/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.2816 - val_loss: 3.5329\n",
      "Epoch 20/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.3049 - val_loss: 3.1998\n",
      "Epoch 21/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4156 - val_loss: 2.8668\n",
      "Epoch 22/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3061 - val_loss: 2.4418\n",
      "Epoch 23/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.0395 - val_loss: 2.1389\n",
      "Epoch 24/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.2546 - val_loss: 1.8045\n",
      "Epoch 25/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6315 - val_loss: 1.4816\n",
      "Epoch 26/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.2836 - val_loss: 1.2007\n",
      "Epoch 27/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.9156 - val_loss: 1.0765\n",
      "Epoch 28/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5545 - val_loss: 0.9603\n",
      "Epoch 29/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.1827 - val_loss: 0.8714\n",
      "Epoch 30/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5229 - val_loss: 0.7992\n",
      "Epoch 31/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4921 - val_loss: 0.7023\n",
      "Epoch 32/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.7496 - val_loss: 0.6300\n",
      "Epoch 33/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4187 - val_loss: 0.5698\n",
      "Epoch 34/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6549 - val_loss: 0.5098\n",
      "Epoch 35/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.3063 - val_loss: 0.4304\n",
      "Epoch 36/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3676 - val_loss: 0.3826\n",
      "Epoch 37/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1916 - val_loss: 0.3626\n",
      "Epoch 38/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4125 - val_loss: 0.3601\n",
      "Epoch 39/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0489 - val_loss: 0.3635\n",
      "Epoch 40/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5444 - val_loss: 0.3725\n",
      "Epoch 41/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0019 - val_loss: 0.3806\n",
      "Epoch 42/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7465 - val_loss: 0.3884\n",
      "Epoch 43/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2220 - val_loss: 0.4005\n",
      "Epoch 44/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8030 - val_loss: 0.4217\n",
      "Epoch 45/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9591 - val_loss: 0.4243\n",
      "Epoch 46/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1268 - val_loss: 0.4119\n",
      "Epoch 47/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6326 - val_loss: 0.4006\n",
      "Epoch 48/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5721 - val_loss: 0.4069\n",
      "Epoch 49/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0156 - val_loss: 0.3890\n",
      "Epoch 50/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7108 - val_loss: 0.3841\n",
      "Epoch 51/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6764 - val_loss: 0.3845\n",
      "Epoch 52/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6904 - val_loss: 0.3744\n",
      "Epoch 53/600\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5802 - val_loss: 0.3719\n",
      "Epoch 54/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.3632\n",
      "Epoch 55/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6291 - val_loss: 0.3484\n",
      "Epoch 56/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.3591\n",
      "Epoch 57/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7312 - val_loss: 0.3881\n",
      "Epoch 58/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6987 - val_loss: 0.3792\n",
      "Epoch 59/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6735 - val_loss: 0.3586\n",
      "Epoch 60/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5474 - val_loss: 0.3694\n",
      "Epoch 61/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8148 - val_loss: 0.3445\n",
      "Epoch 62/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.3454\n",
      "Epoch 63/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.3472\n",
      "Epoch 64/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5019 - val_loss: 0.3264\n",
      "Epoch 65/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - val_loss: 0.3273\n",
      "Epoch 66/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - val_loss: 0.3474\n",
      "Epoch 67/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.3313\n",
      "Epoch 68/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - val_loss: 0.3355\n",
      "Epoch 69/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5476 - val_loss: 0.3438\n",
      "Epoch 70/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5834 - val_loss: 0.3253\n",
      "Epoch 71/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7044 - val_loss: 0.3209\n",
      "Epoch 72/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3228\n",
      "Epoch 73/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3409 - val_loss: 0.3149\n",
      "Epoch 74/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3512 - val_loss: 0.3145\n",
      "Epoch 75/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.3181\n",
      "Epoch 76/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 0.3139\n",
      "Epoch 77/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5022 - val_loss: 0.3088\n",
      "Epoch 78/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5515 - val_loss: 0.2996\n",
      "Epoch 79/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.3005\n",
      "Epoch 80/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3591 - val_loss: 0.3142\n",
      "Epoch 81/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - val_loss: 0.3102\n",
      "Epoch 82/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2949 - val_loss: 0.2978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3678 - val_loss: 0.3106\n",
      "Epoch 84/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3097\n",
      "Epoch 85/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.3020\n",
      "Epoch 86/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3266 - val_loss: 0.2880\n",
      "Epoch 87/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3510 - val_loss: 0.2849\n",
      "Epoch 88/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3049 - val_loss: 0.2951\n",
      "Epoch 89/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - val_loss: 0.2874\n",
      "Epoch 90/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3905 - val_loss: 0.2931\n",
      "Epoch 91/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3850 - val_loss: 0.2879\n",
      "Epoch 92/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3783 - val_loss: 0.2959\n",
      "Epoch 93/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3735 - val_loss: 0.2941\n",
      "Epoch 94/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - val_loss: 0.2930\n",
      "Epoch 95/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.2941\n",
      "Epoch 96/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2902 - val_loss: 0.3027\n",
      "Epoch 97/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2806 - val_loss: 0.2942\n",
      "Epoch 98/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2713 - val_loss: 0.2892\n",
      "Epoch 99/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3249 - val_loss: 0.2886\n",
      "Epoch 100/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3173 - val_loss: 0.2880\n",
      "Epoch 101/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3803 - val_loss: 0.2872\n",
      "Epoch 102/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2785 - val_loss: 0.2848\n",
      "Epoch 103/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3911 - val_loss: 0.2866\n",
      "Epoch 104/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.2901\n",
      "Epoch 105/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.2808\n",
      "Epoch 106/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.2749\n",
      "Epoch 107/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.2860\n",
      "Epoch 108/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2761 - val_loss: 0.2830\n",
      "Epoch 109/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2776 - val_loss: 0.2750\n",
      "Epoch 110/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3122 - val_loss: 0.2762\n",
      "Epoch 111/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2862 - val_loss: 0.2748\n",
      "Epoch 112/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.2713\n",
      "Epoch 113/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3201 - val_loss: 0.2830\n",
      "Epoch 114/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2922 - val_loss: 0.2725\n",
      "Epoch 115/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3139 - val_loss: 0.2759\n",
      "Epoch 116/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3159 - val_loss: 0.2824\n",
      "Epoch 117/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2619 - val_loss: 0.2755\n",
      "Epoch 118/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2862 - val_loss: 0.2729\n",
      "Epoch 119/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2633 - val_loss: 0.2725\n",
      "Epoch 120/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.2705\n",
      "Epoch 121/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3184 - val_loss: 0.2742\n",
      "Epoch 122/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3264 - val_loss: 0.2724\n",
      "Epoch 123/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3520 - val_loss: 0.2680\n",
      "Epoch 124/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2916 - val_loss: 0.2710\n",
      "Epoch 125/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2890 - val_loss: 0.2727\n",
      "Epoch 126/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2681 - val_loss: 0.2701\n",
      "Epoch 127/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2994 - val_loss: 0.2776\n",
      "Epoch 128/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2835 - val_loss: 0.2720\n",
      "Epoch 129/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.2730\n",
      "Epoch 130/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.2675\n",
      "Epoch 131/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2595 - val_loss: 0.2760\n",
      "Epoch 132/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2692 - val_loss: 0.2690\n",
      "Epoch 133/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2617 - val_loss: 0.2688\n",
      "Epoch 134/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3076 - val_loss: 0.2678\n",
      "Epoch 135/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2904 - val_loss: 0.2703\n",
      "Epoch 136/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2564 - val_loss: 0.2715\n",
      "Epoch 137/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2645 - val_loss: 0.2733\n",
      "Epoch 138/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2679 - val_loss: 0.2706\n",
      "Epoch 139/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2581 - val_loss: 0.2678\n",
      "Epoch 140/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2564 - val_loss: 0.2649\n",
      "Epoch 141/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3035 - val_loss: 0.2672\n",
      "Epoch 142/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2760 - val_loss: 0.2647\n",
      "Epoch 143/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2541 - val_loss: 0.2664\n",
      "Epoch 144/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2645 - val_loss: 0.2721\n",
      "Epoch 145/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2720 - val_loss: 0.2693\n",
      "Epoch 146/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2616 - val_loss: 0.2725\n",
      "Epoch 147/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2532 - val_loss: 0.2636\n",
      "Epoch 148/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2668 - val_loss: 0.2642\n",
      "Epoch 149/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2547 - val_loss: 0.2685\n",
      "Epoch 150/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2587 - val_loss: 0.2652\n",
      "Epoch 151/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2744 - val_loss: 0.2650\n",
      "Epoch 152/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2822 - val_loss: 0.2696\n",
      "Epoch 153/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2528 - val_loss: 0.2726\n",
      "Epoch 154/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2653 - val_loss: 0.2641\n",
      "Epoch 155/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2791 - val_loss: 0.2738\n",
      "Epoch 156/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2597 - val_loss: 0.2629\n",
      "Epoch 157/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 0.2711\n",
      "Epoch 158/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2796 - val_loss: 0.2707\n",
      "Epoch 159/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2552 - val_loss: 0.2624\n",
      "Epoch 160/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.2621\n",
      "Epoch 161/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2488 - val_loss: 0.2630\n",
      "Epoch 162/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2496 - val_loss: 0.2654\n",
      "Epoch 163/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2626 - val_loss: 0.2622\n",
      "Epoch 164/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2419 - val_loss: 0.2621\n",
      "Epoch 165/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2559 - val_loss: 0.2619\n",
      "Epoch 166/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2522 - val_loss: 0.2616\n",
      "Epoch 167/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2693 - val_loss: 0.2657\n",
      "Epoch 168/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2532 - val_loss: 0.2626\n",
      "Epoch 169/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2575 - val_loss: 0.2647\n",
      "Epoch 170/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2525 - val_loss: 0.2637\n",
      "Epoch 171/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2557 - val_loss: 0.2628\n",
      "Epoch 172/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2443 - val_loss: 0.2637\n",
      "Epoch 173/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2421 - val_loss: 0.2615\n",
      "Epoch 174/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2437 - val_loss: 0.2614\n",
      "Epoch 175/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2436 - val_loss: 0.2607\n",
      "Epoch 176/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2410 - val_loss: 0.2609\n",
      "Epoch 177/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2466 - val_loss: 0.2607\n",
      "Epoch 178/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.2613\n",
      "Epoch 179/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2488 - val_loss: 0.2611\n",
      "Epoch 180/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2494 - val_loss: 0.2622\n",
      "Epoch 181/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2374 - val_loss: 0.2604\n",
      "Epoch 182/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2604 - val_loss: 0.2605\n",
      "Epoch 183/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2424 - val_loss: 0.2607\n",
      "Epoch 184/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2342 - val_loss: 0.2603\n",
      "Epoch 185/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2454 - val_loss: 0.2602\n",
      "Epoch 186/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2409 - val_loss: 0.2622\n",
      "Epoch 187/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2492 - val_loss: 0.2614\n",
      "Epoch 188/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2370 - val_loss: 0.2600\n",
      "Epoch 189/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2422 - val_loss: 0.2603\n",
      "Epoch 190/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2482 - val_loss: 0.2627\n",
      "Epoch 191/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2348 - val_loss: 0.2603\n",
      "Epoch 192/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2423 - val_loss: 0.2607\n",
      "Epoch 193/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2347 - val_loss: 0.2606\n",
      "Epoch 194/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2542 - val_loss: 0.2645\n",
      "Epoch 195/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2365 - val_loss: 0.2604\n",
      "Epoch 196/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2362 - val_loss: 0.2606\n",
      "Epoch 197/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2351 - val_loss: 0.2602\n",
      "Epoch 198/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2452 - val_loss: 0.2595\n",
      "Epoch 199/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2340 - val_loss: 0.2597\n",
      "Epoch 200/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2407 - val_loss: 0.2596\n",
      "Epoch 201/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2415 - val_loss: 0.2622\n",
      "Epoch 202/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2370 - val_loss: 0.2596\n",
      "Epoch 203/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2349 - val_loss: 0.2602\n",
      "Epoch 204/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2415 - val_loss: 0.2620\n",
      "Epoch 205/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2362 - val_loss: 0.2590\n",
      "Epoch 206/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2406 - val_loss: 0.2594\n",
      "Epoch 207/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2297 - val_loss: 0.2602\n",
      "Epoch 208/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2327 - val_loss: 0.2592\n",
      "Epoch 209/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2428 - val_loss: 0.2617\n",
      "Epoch 210/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2296 - val_loss: 0.2594\n",
      "Epoch 211/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2363 - val_loss: 0.2592\n",
      "Epoch 212/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2405 - val_loss: 0.2594\n",
      "Epoch 213/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2323 - val_loss: 0.2595\n",
      "Epoch 214/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2346 - val_loss: 0.2594\n",
      "Epoch 215/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2344 - val_loss: 0.2600\n",
      "Epoch 216/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2313 - val_loss: 0.2598\n",
      "Epoch 217/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2351 - val_loss: 0.2595\n",
      "Epoch 218/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2333 - val_loss: 0.2599\n",
      "Epoch 219/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2361 - val_loss: 0.2596\n",
      "Epoch 220/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2347 - val_loss: 0.2592\n",
      "Epoch 221/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2412 - val_loss: 0.2597\n",
      "Epoch 222/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2341 - val_loss: 0.2592\n",
      "Epoch 223/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2375 - val_loss: 0.2594\n",
      "Epoch 224/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2351 - val_loss: 0.2592\n",
      "Epoch 225/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2349 - val_loss: 0.2594\n",
      "Epoch 226/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2389 - val_loss: 0.2595\n",
      "Epoch 227/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2368 - val_loss: 0.2595\n",
      "Epoch 228/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2303 - val_loss: 0.2594\n",
      "Epoch 229/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2297 - val_loss: 0.2603\n",
      "Epoch 230/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2422 - val_loss: 0.2600\n",
      "Epoch 230: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdffbfea00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=600,validation_data=(X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d970330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e863dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9293286219081273\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       263\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.93       283\n",
      "   macro avg       0.46      0.50      0.48       283\n",
      "weighted avg       0.86      0.93      0.90       283\n",
      "\n",
      "\n",
      "\n",
      "[[263   0]\n",
      " [ 20   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngoa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ngoa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ngoa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:',accuracy_score(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3804b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e76e7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "98caa44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95833333 0.94444444 0.98611111 0.94444444 0.95833333 0.91549296\n",
      " 0.92957746 0.91549296]\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=8, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "12928e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440287558685445"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6e0dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c9836a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9575971731448764\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       263\n",
      "           1       0.68      0.75      0.71        20\n",
      "\n",
      "    accuracy                           0.96       283\n",
      "   macro avg       0.83      0.86      0.85       283\n",
      "weighted avg       0.96      0.96      0.96       283\n",
      "\n",
      "\n",
      "\n",
      "[[256   7]\n",
      " [  5  15]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:',accuracy_score(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114d4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
